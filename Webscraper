import requests
from bs4 import BeautifulSoup
import sqlite3
import PyPDF2
import os
from urllib.parse import urljoin

response = requests.get('https://httpbin.org/user-agent')
user_agent = response.json()['user-agent']

def getScholarData(url, user_agent=user_agent):
    try:
        headers = {
            "User-Agent": user_agent
        }
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        scholar_results = []

        for el in soup.select(".gs_r")[:3]:  # Limit to top 3 results
            title_link = el.select(".gs_rt a")[0]["href"] if el.select(".gs_rt a") else ""
            # Only process links that end with '.pdf'
            if title_link.lower().endswith('.pdf'):
                scholar_results.append({
                    "title": el.select(".gs_rt")[0].text if el.select(".gs_rt") else None,
                    "title_link": title_link,
                    "id": el.select(".gs_rt a")[0]["id"] if el.select(".gs_rt a") else "",
                    "displayed_link": el.select(".gs_a")[0].text if el.select(".gs_a") else "",
                    "snippet": el.select(".gs_rs")[0].text.replace("\n", "") if el.select(".gs_rs") else "",
                    "cited_by_count": el.select(".gs_nph+ a")[0].text if el.select(".gs_nph+ a") else "",
                    "cited_link": "https://scholar.google.com" + el.select(".gs_nph+ a")[0]["href"] if el.select(".gs_nph+ a") and len(el.select(".gs_nph+ a")) > 0 else None,
                    "versions_count": el.select("a~ a+ .gs_nph")[0].text if el.select("a~ a+ .gs_nph") and len(el.select("a~ a+ .gs_nph")) > 0 else "",
                    "versions_link": "https://scholar.google.com" + el.select("a~ a+ .gs_nph")[0]["href"] if el.select("a~ a+ .gs_nph") and len(el.select("a~ a+ .gs_nph")) > 0 and el.select("a~ a+ .gs_nph")[0].text else "",
                })
        # Filter out items with empty or None values
        for i in range(len(scholar_results)):
            scholar_results[i] = {key: value for key, value in scholar_results[i].items() if value != "" and value is not None}

        return scholar_results
    except requests.exceptions.RequestException as e:
        print(f"Request error: {e}")
        return []
    except Exception as e:
        print(f"An error occurred: {e}")
        return []

def init_db():
    conn = sqlite3.connect('scholar_data.db')
    c = conn.cursor()
    c.execute('''
        CREATE TABLE IF NOT EXISTS scholar_results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            topic TEXT,
            title TEXT,
            title_link TEXT
        )
    ''')
    conn.commit()
    conn.close()

def insert_data(topic, title, title_link):
    conn = sqlite3.connect('scholar_data.db')
    c = conn.cursor()
    c.execute('''
        INSERT INTO scholar_results (topic, title, title_link)
        VALUES (?, ?, ?)
    ''', (topic, title, title_link))
    conn.commit()
    conn.close()

def download_pdf(url, filename, retries=3):
    """Download the PDF with retry logic"""
    for attempt in range(retries):
        try:
            response = requests.get(url)
            response.raise_for_status()
            
            # Check if the response is HTML instead of PDF
            if 'text/html' in response.headers.get('Content-Type', ''):
                print(f"Received HTML response when downloading {url}, skipping.")
                return False

            with open(filename, 'wb') as file:
                file.write(response.content)
            print(f"Downloaded {filename}")
            return True
        except requests.exceptions.RequestException as e:
            print(f"Attempt {attempt + 1} failed: {e}")
    return False

def is_valid_pdf(filename):
    """Check if the file is a valid PDF by verifying the magic number '%PDF'"""
    try:
        with open(filename, 'rb') as file:
            first_bytes = file.read(4)
            if first_bytes != b'%PDF':
                print(f"{filename} is not a valid PDF (magic number mismatch).")
                return False
            return True
    except Exception as e:
        print(f"Error checking validity of {filename}: {e}")
        return False

def is_encrypted_pdf(filename):
    """Check if the PDF is encrypted"""
    try:
        with open(filename, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            if reader.is_encrypted:
                print(f"{filename} is encrypted. Skipping.")
                return True
        return False
    except Exception as e:
        print(f"Error checking encryption for {filename}: {e}")
        return False

def check_pdf_validity(filename):
    """Validate if the PDF is valid using metadata, text extraction, and structure"""
    # Check if the PDF is encrypted
    if is_encrypted_pdf(filename):
        return False
    
    # Check if the file is a valid PDF
    if not is_valid_pdf(filename):
        return False

    try:
        with open(filename, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            
            # Check for the presence of metadata (title, author)
            metadata = reader.metadata
            if not metadata or not metadata.get('Title') or not metadata.get('Author'):
                print(f"Missing metadata in {filename}. Skipping.")
                return False
            
            # Attempt to extract text
            text = ""
            for page_num in range(len(reader.pages)):
                page = reader.pages[page_num]
                text += page.extract_text()
            
            # If no text is extracted, consider it invalid
            if not text.strip():
                print(f"No extractable text in {filename}. Skipping.")
                return False
            
            return True
            
    except Exception as e:
        print(f"Error processing {filename}: {e}")
        return False

def store_pdf_info(db_name, filename, info, text):
    """Store extracted information from the PDF in the database"""
    if not info:
        print(f"Skipping {filename} due to missing info.")
        return  # Skip storing if no info

    conn = sqlite3.connect(db_name)
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS pdfs (
            id INTEGER PRIMARY KEY,
            filename TEXT,
            title TEXT,
            author TEXT,
            subject TEXT,
            text_content TEXT
        )
    ''')
    
    cursor.execute('''
        INSERT INTO pdfs (filename, title, author, subject, text_content)
        VALUES (?, ?, ?, ?, ?)
    ''', (filename, info.title if info.title else "", info.author if info.author else "", info.subject if info.subject else "", text))
    
    conn.commit()
    conn.close()
    print(f"Stored {filename} in {db_name}")

def download_and_store_pdfs(topics):
    """Main function to download, process, and store PDFs"""
    base_url = "https://www.google.com/scholar?q={}&hl=en"
    for topic in topics:
        url = base_url.format(topic.replace(" ", "+"))
        results = getScholarData(url)
        for result in results:
            # Download the PDF
            pdf_url = result['title_link']
            pdf_url = urljoin("https://scholar.google.com", pdf_url)  # Ensure the URL is absolute
            filename = os.path.basename(pdf_url)
            
            # Check if PDF is valid
            if download_pdf(pdf_url, filename) and check_pdf_validity(filename):
                # Extract info and text from the valid PDF
                with open(filename, 'rb') as file:
                    reader = PyPDF2.PdfReader(file)
                    info = reader.metadata
                    text = ""
                    for page_num in range(len(reader.pages)):
                        page = reader.pages[page_num]
                        text += page.extract_text()

                    store_pdf_info('pdfs.db', filename, info, text)
                    insert_data(topic, result['title'], result['title_link'])
            
            # Clean up by removing the downloaded file
            if os.path.exists(filename):
                os.remove(filename)
                print(f"Deleted {filename} after processing.")

init_db()
topics = ["Medical Devices", "Artificial Intelligence"]
download_and_store_pdfs(topics)
